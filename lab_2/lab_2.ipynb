{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python376jvsc74a57bd0b8f2a64b4d874d86bac9a28df61c451282f1015b12be6fd8db703c9049d6db33",
      "display_name": "Python 3.7.6 64-bit ('base': conda)"
    },
    "metadata": {
      "interpreter": {
        "hash": "b8f2a64b4d874d86bac9a28df61c451282f1015b12be6fd8db703c9049d6db33"
      }
    },
    "colab": {
      "name": "ML_lab_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "asJoJLElFOtq"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sXJzeIeEFOt2",
        "outputId": "e772f215-41b1-4118-cd6e-9742fdbaf05a"
      },
      "source": [
        "df_train = pd.read_csv('./train.csv')\n",
        "df_test = pd.read_csv('./test.csv')\n",
        "gen_submission = pd.read_csv('./gender_submission.csv')\n",
        "\n",
        "df_test['Survived'] = gen_submission['Survived']\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "4      0            373450   8.0500   NaN        S  "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPTci8ZHFOt5"
      },
      "source": [
        "Преобразуем данные, чтобы получить готовый датасет из предыдущей лабораторной."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYvA5LCUFOt-"
      },
      "source": [
        "for df in [df_train, df_test]:\n",
        "    mean = df['Age'].mean()\n",
        "    std = df['Age'].std()\n",
        "    number_of_nulls = df['Age'].isnull().sum()\n",
        "    random_ages = np.random.randint(mean - std, mean + std, size=number_of_nulls)\n",
        "\n",
        "    new_ages = df['Age'].copy()\n",
        "    new_ages[np.isnan(new_ages)] = random_ages\n",
        "    df['Age'] = new_ages\n",
        "\n",
        "for df in [df_train, df_test]:\n",
        "    df['Embarked'] = df['Embarked'].fillna('S')\n",
        "\n",
        "df_test = df_test[df_test['Fare'].notnull()]\n",
        "\n",
        "df_train = df_train.drop(columns=['Name', 'PassengerId', 'Ticket', 'Cabin'])\n",
        "df_test = df_test.drop(columns=['Name', 'PassengerId', 'Ticket', 'Cabin'])\n",
        "\n",
        "df_train['Relatives'] = df_train['Parch'] + df_train['SibSp']\n",
        "df_test['Relatives'] = df_test['Parch'] + df_test['SibSp']\n",
        "df_train = df_train.drop(columns=['SibSp', 'Parch'])\n",
        "df_test = df_test.drop(columns=['SibSp', 'Parch'])\n",
        "\n",
        "genders = {'male': 0, 'female': 1}\n",
        "ports = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
        "for df in [df_train, df_test]:\n",
        "    df['Sex'] = df['Sex'].map(genders)\n",
        "    df['Embarked'] = df['Embarked'].map(ports)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WKB87c75FOuI",
        "outputId": "100c6c28-4582-473e-a487-58aae1a3593e"
      },
      "source": [
        "X_train = df_train.drop(columns=['Survived']).to_numpy()\n",
        "Y_train = df_train['Survived'].to_numpy()\n",
        "\n",
        "X_test = df_test.drop(columns=['Survived']).to_numpy()\n",
        "Y_test = df_test['Survived'].to_numpy()\n",
        "\n",
        "df_test.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pclass  Sex   Age     Fare  Embarked  Survived  Relatives\n",
              "0       3    0  34.5   7.8292         2         0          0\n",
              "1       3    1  47.0   7.0000         0         1          1\n",
              "2       2    0  62.0   9.6875         2         0          0\n",
              "3       3    0  27.0   8.6625         0         0          0\n",
              "4       3    1  22.0  12.2875         0         1          2"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>Survived</th>\n      <th>Relatives</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>0</td>\n      <td>34.5</td>\n      <td>7.8292</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>1</td>\n      <td>47.0</td>\n      <td>7.0000</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>62.0</td>\n      <td>9.6875</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>27.0</td>\n      <td>8.6625</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>1</td>\n      <td>22.0</td>\n      <td>12.2875</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSKglH5M3qn3"
      },
      "source": [
        "Вспомогательные функции для анализа результатов классификации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPXUBizU3qn4"
      },
      "source": [
        "def confusion_matrix(y_pred, y_test):\n",
        "    matrix = pd.DataFrame({'actual_1' : [0, 0], 'actual_0': [0, 0]})\n",
        "    matrix.index = ['predicted_1', 'predicted_0']\n",
        "\n",
        "    for i in range(len(y_pred)):\n",
        "        if y_pred[i] == 1 and y_test[i] == 1:\n",
        "            matrix.loc['predicted_1', 'actual_1'] += 1\n",
        "        elif y_pred[i] == 1 and y_test[i] == 0:\n",
        "            matrix.loc['predicted_1', 'actual_0'] += 1\n",
        "        elif y_pred[i] == 0 and y_test[i] == 1:\n",
        "            matrix.loc['predicted_0', 'actual_1'] += 1\n",
        "        else:\n",
        "            matrix.loc['predicted_0', 'actual_0'] += 1\n",
        "\n",
        "    return matrix\n",
        "\n",
        "def metrics(matrix):\n",
        "    TP = matrix.loc['predicted_1', 'actual_1']\n",
        "    FP = matrix.loc['predicted_1', 'actual_0']\n",
        "    FN = matrix.loc['predicted_0', 'actual_1']\n",
        "    TN = matrix.loc['predicted_0', 'actual_0']\n",
        "\n",
        "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "    precision = TP / (TP + FP)\n",
        "    recall = TP / (TP + FN)\n",
        "\n",
        "    return accuracy, precision, recall"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MGC-PFQFOuI"
      },
      "source": [
        "\n",
        "## 1. Логистическая регрессия"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDLC9RSVFOuI"
      },
      "source": [
        "class my_Logistic_Regression():\n",
        "    def __init__(self, learning_rate, n_iterations):        \n",
        "        self.learning_rate = learning_rate        \n",
        "        self.n_iterations = n_iterations\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        self.X = X.copy()\n",
        "        self.Y = Y.copy()\n",
        "        n_samples, n_features = X.shape     \n",
        "        self.W = np.zeros(n_features)        \n",
        "        self.b = 0\n",
        "\n",
        "        # обновление весов с помощью градиентного спуска\n",
        "        for _ in range(self.n_iterations):\n",
        "            linear_model = np.dot(self.X, self.W) + self.b          \n",
        "            y_predicted = 1 / (1 + np.exp(-linear_model))\n",
        "\n",
        "            dW = (1 / n_samples) * np.dot(X.T, y_predicted - Y)\n",
        "            db = (1 / n_samples) * np.sum(y_predicted - Y)\n",
        "            self.W -= self.learning_rate * dW    \n",
        "            self.b -= self.learning_rate * db  \n",
        "\n",
        "    def predict(self, X):\n",
        "        S = np.array(1 / (1 + np.exp(-(np.dot(X, self.W) + self.b))))\n",
        "        # если сигмойд получается больше, чем 0.5, то предсказываем класс 1\n",
        "        return np.where(S >= 0.5, 1, 0)"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YxaqAi23qn9",
        "outputId": "aa821255-41be-49c1-8b6a-7fcf0ed8f058"
      },
      "source": [
        "hyperparameters = [\n",
        "(0.1, 500), \n",
        "(0.1, 1000), \n",
        "(0.1, 1500),\n",
        "(0.01, 1000),\n",
        "(0.01, 2000),\n",
        "(0.01, 5000),\n",
        "(0.01, 10000),\n",
        "(0.001, 1000),\n",
        "(0.001, 3000),\n",
        "(0.001, 5000),\n",
        "(0.001, 10000),\n",
        "(0.001, 15000),\n",
        "(0.0001, 2000),\n",
        "(0.0001, 5000),\n",
        "(0.0001, 10000),\n",
        "(0.0001, 15000),\n",
        "(0.0001, 20000),\n",
        "(0.0001, 50000)\n",
        "]\n",
        "\n",
        "for pair in hyperparameters:\n",
        "    lr, iters = pair\n",
        "    my_log_regr = my_Logistic_Regression(learning_rate=lr, n_iterations=iters)\n",
        "    my_log_regr.fit(X_train, Y_train)\n",
        "    Y_pred_test = my_log_regr.predict(X_test)\n",
        "    Y_pred_train = my_log_regr.predict(X_train)\n",
        "    print(f'Learning rate = {lr}, iterations = {iters}, train accuracy = {np.mean(Y_train == Y_pred_train)}, test accuracy = {np.mean(Y_test == Y_pred_test)}')\n"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate = 0.1, iterations = 500, train accuracy = 0.7182940516273849, test accuracy = 0.6738609112709832\n",
            "Learning rate = 0.1, iterations = 1000, train accuracy = 0.7418630751964085, test accuracy = 0.7194244604316546\n",
            "Learning rate = 0.1, iterations = 1500, train accuracy = 0.7609427609427609, test accuracy = 0.7697841726618705\n",
            "Learning rate = 0.01, iterations = 1000, train accuracy = 0.6161616161616161, test accuracy = 0.6354916067146283\n",
            "Learning rate = 0.01, iterations = 2000, train accuracy = 0.6464646464646465, test accuracy = 0.6594724220623501\n",
            "Learning rate = 0.01, iterations = 5000, train accuracy = 0.7216610549943884, test accuracy = 0.7721822541966427\n",
            "Learning rate = 0.01, iterations = 10000, train accuracy = 0.7575757575757576, test accuracy = 0.8345323741007195\n",
            "Learning rate = 0.001, iterations = 1000, train accuracy = 0.6879910213243546, test accuracy = 0.6522781774580336\n",
            "Learning rate = 0.001, iterations = 3000, train accuracy = 0.6992143658810326, test accuracy = 0.6738609112709832\n",
            "Learning rate = 0.001, iterations = 5000, train accuracy = 0.712682379349046, test accuracy = 0.6954436450839329\n",
            "Learning rate = 0.001, iterations = 10000, train accuracy = 0.7575757575757576, test accuracy = 0.7769784172661871\n",
            "Learning rate = 0.001, iterations = 15000, train accuracy = 0.7968574635241302, test accuracy = 0.841726618705036\n",
            "Learning rate = 0.0001, iterations = 2000, train accuracy = 0.6801346801346801, test accuracy = 0.6618705035971223\n",
            "Learning rate = 0.0001, iterations = 5000, train accuracy = 0.6868686868686869, test accuracy = 0.6618705035971223\n",
            "Learning rate = 0.0001, iterations = 10000, train accuracy = 0.6879910213243546, test accuracy = 0.6522781774580336\n",
            "Learning rate = 0.0001, iterations = 15000, train accuracy = 0.691358024691358, test accuracy = 0.6522781774580336\n",
            "Learning rate = 0.0001, iterations = 20000, train accuracy = 0.6924803591470258, test accuracy = 0.6666666666666666\n",
            "Learning rate = 0.0001, iterations = 50000, train accuracy = 0.712682379349046, test accuracy = 0.6954436450839329\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scu_LdAQ3qoB"
      },
      "source": [
        "Лучшую точность показала модель с learning rate, равным 0.001 и количеством итераций, равным 15000. Посмотрим на результаты классификации для моей модели с такими гиперпараметрами."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4YFlBP2FOuJ"
      },
      "source": [
        "mylogit = my_Logistic_Regression(learning_rate=0.001, n_iterations=15000)\n",
        "mylogit.fit(X_train, Y_train)\n",
        "Y_pred = mylogit.predict(X_test)"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfUV2uhOFOuJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "07988708-9bf0-411f-9cd2-4e4e538c30ed"
      },
      "source": [
        "confusion_matrix(Y_pred, Y_test)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual_1</th>\n",
              "      <th>actual_0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>predicted_1</th>\n",
              "      <td>102</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>predicted_0</th>\n",
              "      <td>50</td>\n",
              "      <td>249</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             actual_1  actual_0\n",
              "predicted_1       102        16\n",
              "predicted_0        50       249"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DMvr9Si3qoG",
        "outputId": "716a3b4d-f76c-48dc-ab5c-d90e0283d822"
      },
      "source": [
        "metrics_mylogreg = metrics(confusion_matrix(Y_pred, Y_test))\n",
        "print(f'Accuracy: {metrics_mylogreg[0]}\\nPrecision: {metrics_mylogreg[1]}\\nRecall: {metrics_mylogreg[2]}')"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.841726618705036\n",
            "Precision: 0.864406779661017\n",
            "Recall: 0.6710526315789473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsvhtO_h3qoG"
      },
      "source": [
        "Мы получили довольно низкий recall. Это значит (и видно из таблицы), что модель предсказала малую долю выживших людей, то есть много выживших она определила как погибших."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCKutVHM3qoH"
      },
      "source": [
        "Теперь посмотрим на модель из sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n59LnDc93qoI"
      },
      "source": [
        "logreg_model = LogisticRegression().fit(X_train, Y_train)\n",
        "Y_pred = logreg_model.predict(X_test)"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "n1Os6l253qoJ",
        "outputId": "88a3e3e1-8cde-40e6-8e46-801dbe815668"
      },
      "source": [
        "confusion_matrix(Y_pred, Y_test)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual_1</th>\n",
              "      <th>actual_0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>predicted_1</th>\n",
              "      <td>139</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>predicted_0</th>\n",
              "      <td>13</td>\n",
              "      <td>250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             actual_1  actual_0\n",
              "predicted_1       139        15\n",
              "predicted_0        13       250"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_FXA3YM3qoK",
        "outputId": "69a4d476-5c9e-42fd-824f-f3d52b4dd447"
      },
      "source": [
        "metrics_sklogreg = metrics(confusion_matrix(Y_pred, Y_test))\n",
        "print(f'Accuracy: {metrics_sklogreg[0]}\\nPrecision: {metrics_sklogreg[1]}\\nRecall: {metrics_sklogreg[2]}')"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9328537170263789\n",
            "Precision: 0.9025974025974026\n",
            "Recall: 0.9144736842105263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8C9y0gd3qoL"
      },
      "source": [
        "Мы видим, что модель логистический регрессии из sklearn справилась немного лучше, чем реализованная. Причем recall получился немного выше, чем precision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzffDebHbizn"
      },
      "source": [
        "## 2. SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inEQMifX3qoM"
      },
      "source": [
        "class my_SVM:\n",
        "    def __init__(self, learning_rate=0.01, lambda_param=0.01, n_iters=10000):\n",
        "        self.lr = learning_rate\n",
        "        self.lambda_param = lambda_param\n",
        "        self.n_iters = n_iters\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # переименовываем лейблы в -1 и 1\n",
        "        y_ = np.where(y <= 0, -1, 1)\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        self.W = np.zeros(n_features)\n",
        "        self.b = 0\n",
        "\n",
        "        # процесс обучения (настройка весов и смещения)\n",
        "        for _ in range(self.n_iters):\n",
        "            for idx, x_i in enumerate(X):\n",
        "                condition = y_[idx] * ((x_i @ self.W) - self.b) >= 1\n",
        "                if condition:\n",
        "                    self.W -= self.lr * (2 * self.lambda_param * self.W)\n",
        "                else:\n",
        "                    self.W -= self.lr * (2 * self.lambda_param * self.W - np.dot(x_i,y_[idx]))\n",
        "                    self.b -= self.lr * y_[idx]\n",
        "\n",
        "    def predict(self, X):\n",
        "        res = np.dot(X, self.W) - self.b\n",
        "        # предсказываем класс в зависимости от знака\n",
        "        return np.where(res >= 0, 1, 0)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwDWIRl33qoN"
      },
      "source": [
        "Попробуем подобрать гиперпараметры. Проведя некоторые тесты, лямбду я взял везде одинаковую, равную 0.01."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3IqxANv3qoO",
        "outputId": "ac29a8e8-bccb-42bb-fd0e-c95f105cacff"
      },
      "source": [
        "hyperparameters = [\n",
        "(0.01, 0.01, 2000),\n",
        "(0.01, 0.01, 5000),\n",
        "(0.001, 0.01, 1000),\n",
        "(0.001, 0.01, 3000),\n",
        "(0.001, 0.01, 5000),\n",
        "(0.001, 0.01, 10000),\n",
        "(0.001, 0.01, 15000),\n",
        "(0.0001, 0.01, 5000),\n",
        "(0.0001, 0.01, 10000),\n",
        "(0.0001, 0.01, 15000),\n",
        "]\n",
        "\n",
        "for h in hyperparameters:\n",
        "    lr, lambda_param, iters = h\n",
        "    my_svm = my_SVM(learning_rate=lr, lambda_param=lambda_param, n_iters=iters)\n",
        "    my_svm.fit(X_train, Y_train)\n",
        "    print(f'Learning rate = {lr}, lambda = {lambda_param}, iterations = {iters}, train accuracy = {np.mean(Y_train == my_svm.predict(X_train))}, test accuracy = {np.mean(Y_test == my_svm.predict(X_test))}')\n"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate = 0.01, lambda = 0.01, iterations = 2000, train accuracy = 0.7216610549943884, test accuracy = 0.6906474820143885\n",
            "Learning rate = 0.01, lambda = 0.01, iterations = 5000, train accuracy = 0.7373737373737373, test accuracy = 0.7338129496402878\n",
            "Learning rate = 0.001, lambda = 0.01, iterations = 1000, train accuracy = 0.7620650953984287, test accuracy = 0.8369304556354916\n",
            "Learning rate = 0.001, lambda = 0.01, iterations = 3000, train accuracy = 0.7878787878787878, test accuracy = 0.8585131894484412\n",
            "Learning rate = 0.001, lambda = 0.01, iterations = 5000, train accuracy = 0.7777777777777778, test accuracy = 0.841726618705036\n",
            "Learning rate = 0.001, lambda = 0.01, iterations = 10000, train accuracy = 0.7856341189674523, test accuracy = 0.8561151079136691\n",
            "Learning rate = 0.001, lambda = 0.01, iterations = 15000, train accuracy = 0.7485970819304153, test accuracy = 0.7529976019184652\n",
            "Learning rate = 0.0001, lambda = 0.01, iterations = 5000, train accuracy = 0.8002244668911336, test accuracy = 0.9232613908872902\n",
            "Learning rate = 0.0001, lambda = 0.01, iterations = 10000, train accuracy = 0.7912457912457912, test accuracy = 0.8992805755395683\n",
            "Learning rate = 0.0001, lambda = 0.01, iterations = 15000, train accuracy = 0.7912457912457912, test accuracy = 0.9064748201438849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWJ93POd3qoO"
      },
      "source": [
        "Рассмотрим модель с параметрами (0.0001, 0.01, 5000)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TkIvrdy3qoP"
      },
      "source": [
        "my_svm = my_SVM(learning_rate=0.0001, lambda_param=0.01, n_iters=5000)\n",
        "my_svm.fit(X_train, Y_train)\n",
        "Y_pred = my_svm.predict(X_test)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "dMfX1IkC3qoP",
        "outputId": "75e748c3-e561-42f8-a677-dd2b388d73fb"
      },
      "source": [
        "confusion_matrix(Y_pred, Y_test)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual_1</th>\n",
              "      <th>actual_0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>predicted_1</th>\n",
              "      <td>139</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>predicted_0</th>\n",
              "      <td>13</td>\n",
              "      <td>250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             actual_1  actual_0\n",
              "predicted_1       139        15\n",
              "predicted_0        13       250"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1ThDJXe3qoR",
        "outputId": "1138bdfb-2dcb-4ce8-8ec8-a372ec65dfad"
      },
      "source": [
        "metrics_my_svm = metrics(confusion_matrix(Y_pred, Y_test))\n",
        "print(f'Accuracy: {metrics_my_svm[0]}\\nPrecision: {metrics_my_svm[1]}\\nRecall: {metrics_my_svm[2]}')"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9328537170263789\n",
            "Precision: 0.9025974025974026\n",
            "Recall: 0.9144736842105263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9iQ-9Vb3qoS"
      },
      "source": [
        "Посмотрим на модель SVM из sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io_6neKd3qoT"
      },
      "source": [
        "sklearn_svm_model = SVC()\n",
        "sklearn_svm_model.fit(X_train, Y_train)\n",
        "Y_pred = sklearn_svm_model.predict(X_test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "TyKRg2cS3qoU",
        "outputId": "bf218950-4f6c-4642-98e9-f0b3367fe9d1"
      },
      "source": [
        "confusion_matrix(Y_pred, Y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             actual_1  actual_0\n",
              "predicted_1        41        35\n",
              "predicted_0       111       230"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>actual_1</th>\n      <th>actual_0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>predicted_1</th>\n      <td>41</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>predicted_0</th>\n      <td>111</td>\n      <td>230</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0GsBq-i3qoV",
        "outputId": "ec4ea223-ab9a-427c-d66c-9798dc0db14f"
      },
      "source": [
        "metrics_sklearn_svm = metrics(confusion_matrix(Y_pred, Y_test))\n",
        "print(f'Accuracy: {metrics_sklearn_svm[0]}\\nPrecision: {metrics_sklearn_svm[1]}\\nRecall: {metrics_sklearn_svm[2]}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6498800959232613\nPrecision: 0.5394736842105263\nRecall: 0.26973684210526316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             actual_1  actual_0\n",
              "predicted_1       115         7\n",
              "predicted_0        37       258"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>actual_1</th>\n      <th>actual_0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>predicted_1</th>\n      <td>115</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>predicted_0</th>\n      <td>37</td>\n      <td>258</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# С нормализацией данных по столбцам\n",
        "X_train_normalized = np.apply_along_axis(lambda x: (x-x.mean())/ x.std(), 0, X_train)\n",
        "X_test_normalized = np.apply_along_axis(lambda x: (x-x.mean())/ x.std(), 0, X_test)\n",
        "\n",
        "sklearn_svm_model = SVC()\n",
        "sklearn_svm_model.fit(X_train_normalized, Y_train)\n",
        "Y_pred = sklearn_svm_model.predict(X_test_normalized)\n",
        "confusion_matrix(Y_pred, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.894484412470024\nPrecision: 0.9426229508196722\nRecall: 0.756578947368421\n"
          ]
        }
      ],
      "source": [
        "metrics_sklearn_svm = metrics(confusion_matrix(Y_pred, Y_test))\n",
        "print(f'Accuracy: {metrics_sklearn_svm[0]}\\nPrecision: {metrics_sklearn_svm[1]}\\nRecall: {metrics_sklearn_svm[2]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgCU0m6r4xqH"
      },
      "source": [
        "Мы видим, что нормализация данных сильно улучшила качество классификации. Подберем гиперпараметры с помощью RandomizedSearchCV."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-1RDuaE43uE",
        "outputId": "8f3a2c61-800c-4648-ce62-23f8104a35c4"
      },
      "source": [
        "def svc_param_selection(X, y):\n",
        "    Cs = [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "    gammas = [0.001, 0.01, 0.1, 1]\n",
        "    kernels = ['linear', 'rbf']\n",
        "    param_grid = {'C': Cs, 'gamma' : gammas, 'kernel': kernels}\n",
        "    search = RandomizedSearchCV(SVC(), param_grid)\n",
        "    search.fit(X, y)\n",
        "    search.best_params_\n",
        "    return search.best_params_\n",
        "\n",
        "svc_param_selection(X_train_normalized, Y_train)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kernel': 'rbf', 'gamma': 0.01, 'C': 100}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIZ3Xjm65vhM"
      },
      "source": [
        "sklearn_svm_model = SVC(kernel='rbf', gamma=0.01, C=100)\n",
        "sklearn_svm_model.fit(X_train_normalized, Y_train)\n",
        "Y_pred = sklearn_svm_model.predict(X_test_normalized)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "QTSom5IH52-p",
        "outputId": "a96d8e1f-348e-4cd5-bd07-e0597d8bacb3"
      },
      "source": [
        "confusion_matrix(Y_pred, Y_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             actual_1  actual_0\n",
              "predicted_1       135         3\n",
              "predicted_0        17       262"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>actual_1</th>\n      <th>actual_0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>predicted_1</th>\n      <td>135</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>predicted_0</th>\n      <td>17</td>\n      <td>262</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnOpz17c53IJ",
        "outputId": "36bf5c91-8011-4894-9cce-e1fc2038c2a3"
      },
      "source": [
        "metrics_sklearn_svm = metrics(confusion_matrix(Y_pred, Y_test))\n",
        "print(f'Accuracy: {metrics_sklearn_svm[0]}\\nPrecision: {metrics_sklearn_svm[1]}\\nRecall: {metrics_sklearn_svm[2]}')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9520383693045563\nPrecision: 0.9782608695652174\nRecall: 0.8881578947368421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRpveJs4bpDd"
      },
      "source": [
        "## 3. Дерево решений"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdEgTem_3qoX"
      },
      "source": [
        "class Node():\n",
        "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
        "        # для внутренней вершины\n",
        "        self.feature_index = feature_index\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.info_gain = info_gain\n",
        "        # для листа\n",
        "        self.value = value\n",
        "\n",
        "\n",
        "class my_DecisionTreeClassifier():\n",
        "    def __init__(self, min_samples_split=2, max_depth=2):\n",
        "        self.root = None\n",
        "\n",
        "        # гиперпараметры для ограничения построения дерева\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        \n",
        "    def build_tree(self, dataset, curr_depth=0):\n",
        "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
        "        num_samples, num_features = np.shape(X)\n",
        "        \n",
        "        # рекурсивная процедура разделения узлов, зависит от гиперпараметров\n",
        "        if num_samples >= self.min_samples_split and curr_depth <= self.max_depth:\n",
        "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
        "            \n",
        "            # если это условие не выполняется, то мы хотим разделить узел, который и так отвечает за 1 класс\n",
        "            if best_split['info_gain'] > 0:\n",
        "                left_subtree = self.build_tree(best_split['dataset_left'], curr_depth + 1)\n",
        "                right_subtree = self.build_tree(best_split['dataset_right'], curr_depth + 1)\n",
        "                return Node(best_split['feature_index'], best_split['threshold'], \n",
        "                                left_subtree, right_subtree, best_split['info_gain'])\n",
        "        \n",
        "        leaf_value = max(list(Y), key=list(Y).count)\n",
        "        # возвращаем лист\n",
        "        return Node(value=leaf_value)\n",
        "    \n",
        "    def get_best_split(self, dataset, num_samples, num_features):\n",
        "        ''' Жадно находит лучший способ разделения узла '''\n",
        "        best_split = {}\n",
        "        max_info_gain = -float('inf')\n",
        "        \n",
        "        for feature_index in range(num_features):\n",
        "            feature_values = dataset[:, feature_index]\n",
        "            for threshold in np.unique(feature_values):\n",
        "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
        "                if len(dataset_left) > 0 and len(dataset_right) > 0:\n",
        "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
        "                    curr_info_gain = self.information_gain(y, left_y, right_y)\n",
        "                    \n",
        "                    # если получили лучший вариант разделения, то обновляем старые параметры\n",
        "                    if curr_info_gain > max_info_gain:\n",
        "                        best_split['feature_index'] = feature_index\n",
        "                        best_split['threshold'] = threshold\n",
        "                        best_split['dataset_left'] = dataset_left\n",
        "                        best_split['dataset_right'] = dataset_right\n",
        "                        best_split['info_gain'] = curr_info_gain\n",
        "                        max_info_gain = curr_info_gain\n",
        "\n",
        "        return best_split\n",
        "    \n",
        "\n",
        "    def split(self, dataset, feature_index, threshold):\n",
        "        dataset_left = np.array([row for row in dataset if row[feature_index] <= threshold])\n",
        "        dataset_right = np.array([row for row in dataset if row[feature_index] > threshold])\n",
        "        return dataset_left, dataset_right\n",
        "    \n",
        "    def information_gain(self, parent, l_child, r_child):\n",
        "        weight_l = len(l_child) / len(parent)\n",
        "        weight_r = len(r_child) / len(parent)\n",
        "        gain = self.entropy(parent) - (weight_l * self.entropy(l_child) + weight_r * self.entropy(r_child))\n",
        "        return gain\n",
        "    \n",
        "    def entropy(self, y):\n",
        "        class_labels = np.unique(y)\n",
        "        entropy = 0\n",
        "        for cls in class_labels:\n",
        "            p_cls = len(y[y == cls]) / len(y)\n",
        "            entropy += -p_cls * np.log2(p_cls)\n",
        "        return entropy\n",
        "        \n",
        "    def fit(self, X, Y):\n",
        "        dataset = np.concatenate((X, Y), axis=1)\n",
        "        self.root = self.build_tree(dataset)\n",
        "    \n",
        "    def predict(self, X):\n",
        "        preditions = [self.make_prediction(x, self.root) for x in X]\n",
        "        return preditions\n",
        "    \n",
        "    def make_prediction(self, x, tree):\n",
        "        ''' Предсказание для одного наблюдения '''\n",
        "        if tree.value != None: \n",
        "            return tree.value\n",
        "        \n",
        "        feature_val = x[tree.feature_index]\n",
        "        if feature_val<=tree.threshold:\n",
        "            return self.make_prediction(x, tree.left)\n",
        "        else:\n",
        "            return self.make_prediction(x, tree.right)"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ1WOZeNseuE",
        "outputId": "73ee3b03-3182-4402-8f90-cc47dade3cf3"
      },
      "source": [
        "hyperparams = [(i, j) for i in range(2, 4) for j in range(1, 4)]\n",
        "results_mytree = []\n",
        "\n",
        "for h in hyperparams:\n",
        "    min_samples_split, max_depth = h\n",
        "    mytree = my_DecisionTreeClassifier(min_samples_split, max_depth)\n",
        "    mytree.fit(pd.DataFrame(X_train), pd.DataFrame(Y_train))\n",
        "    results_mytree.append([min_samples_split, max_depth, np.mean(mytree.predict(X_train) == Y_train), np.mean(mytree.predict(X_test) == Y_test)])\n",
        "\n",
        "results_mytree.sort(key=lambda x: x[3], reverse=True)\n",
        "results_mytree"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 1, 0.7867564534231201, 1.0],\n",
              " [3, 1, 0.7867564534231201, 1.0],\n",
              " [2, 2, 0.8226711560044894, 0.9640287769784173],\n",
              " [3, 2, 0.8226711560044894, 0.9640287769784173],\n",
              " [2, 3, 0.835016835016835, 0.8776978417266187],\n",
              " [3, 3, 0.835016835016835, 0.8776978417266187]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "a50f4o0C8zWm",
        "outputId": "9d6a9bac-31ca-41bb-d804-167f2474758c"
      },
      "source": [
        "mytree = my_DecisionTreeClassifier(min_samples_split=1, max_depth=1)\n",
        "mytree.fit(pd.DataFrame(X_train), pd.DataFrame(Y_train))\n",
        "confusion_matrix(mytree.predict(X_test), Y_test)"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual_1</th>\n",
              "      <th>actual_0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>predicted_1</th>\n",
              "      <td>152</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>predicted_0</th>\n",
              "      <td>0</td>\n",
              "      <td>265</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             actual_1  actual_0\n",
              "predicted_1       152         0\n",
              "predicted_0         0       265"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6pC5hRt8zfr",
        "outputId": "3a12965f-dcb1-4ebe-a887-916d302c83b3"
      },
      "source": [
        "metrics_mytree = metrics(confusion_matrix(mytree.predict(X_test), Y_test))\n",
        "print(f'Accuracy: {metrics_mytree[0]}\\nPrecision: {metrics_mytree[1]}\\nRecall: {metrics_mytree[2]}')"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrN9fnlSbscQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6393eef-a005-423d-8db2-62dd5520b89d"
      },
      "source": [
        "hyperparams = [(i, j) for i in range(2, 15) for j in range(1, 15)]\n",
        "results_sktree = []\n",
        "\n",
        "for h in hyperparams:\n",
        "    min_samples_split, max_depth = h\n",
        "    sktree = DecisionTreeClassifier(criterion='entropy', min_samples_split=min_samples_split, max_depth=max_depth)\n",
        "    sktree.fit(pd.DataFrame(X_train), pd.DataFrame(Y_train))\n",
        "    results_sktree.append([min_samples_split, max_depth, np.mean(sktree.predict(X_train) == Y_train), np.mean(sktree.predict(X_test) == Y_test)])\n",
        "\n",
        "results_sktree.sort(key=lambda x: x[3], reverse=True)\n",
        "results_sktree"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 1, 0.7867564534231201, 1.0],\n",
              " [3, 1, 0.7867564534231201, 1.0],\n",
              " [4, 1, 0.7867564534231201, 1.0],\n",
              " [5, 1, 0.7867564534231201, 1.0],\n",
              " [6, 1, 0.7867564534231201, 1.0],\n",
              " [7, 1, 0.7867564534231201, 1.0],\n",
              " [8, 1, 0.7867564534231201, 1.0],\n",
              " [9, 1, 0.7867564534231201, 1.0],\n",
              " [10, 1, 0.7867564534231201, 1.0],\n",
              " [11, 1, 0.7867564534231201, 1.0],\n",
              " [12, 1, 0.7867564534231201, 1.0],\n",
              " [13, 1, 0.7867564534231201, 1.0],\n",
              " [14, 1, 0.7867564534231201, 1.0],\n",
              " [5, 3, 0.8226711560044894, 0.9640287769784173],\n",
              " [7, 3, 0.8226711560044894, 0.9640287769784173],\n",
              " [9, 3, 0.8226711560044894, 0.9640287769784173],\n",
              " [10, 3, 0.8226711560044894, 0.9640287769784173],\n",
              " [11, 3, 0.8226711560044894, 0.9640287769784173],\n",
              " [13, 3, 0.8226711560044894, 0.9640287769784173],\n",
              " [14, 3, 0.8226711560044894, 0.9640287769784173],\n",
              " [2, 3, 0.8226711560044894, 0.9616306954436451],\n",
              " [3, 3, 0.8226711560044894, 0.9616306954436451],\n",
              " [4, 3, 0.8226711560044894, 0.9616306954436451],\n",
              " [6, 3, 0.8226711560044894, 0.9616306954436451],\n",
              " [8, 3, 0.8226711560044894, 0.9616306954436451],\n",
              " [12, 3, 0.8226711560044894, 0.9616306954436451],\n",
              " [2, 4, 0.8327721661054994, 0.9592326139088729],\n",
              " [3, 4, 0.8327721661054994, 0.9592326139088729],\n",
              " [4, 4, 0.8327721661054994, 0.9592326139088729],\n",
              " [5, 4, 0.8327721661054994, 0.9592326139088729],\n",
              " [7, 4, 0.8327721661054994, 0.9592326139088729],\n",
              " [14, 5, 0.8451178451178452, 0.9496402877697842],\n",
              " [3, 5, 0.8473625140291807, 0.947242206235012],\n",
              " [4, 5, 0.8473625140291807, 0.947242206235012],\n",
              " [6, 5, 0.8462401795735129, 0.947242206235012],\n",
              " [9, 5, 0.8462401795735129, 0.947242206235012],\n",
              " [11, 5, 0.8462401795735129, 0.947242206235012],\n",
              " [12, 5, 0.8462401795735129, 0.947242206235012],\n",
              " [14, 6, 0.8507295173961841, 0.935251798561151],\n",
              " [3, 6, 0.8552188552188552, 0.9328537170263789],\n",
              " [4, 6, 0.8552188552188552, 0.9328537170263789],\n",
              " [6, 6, 0.8540965207631874, 0.9328537170263789],\n",
              " [8, 6, 0.8540965207631874, 0.9328537170263789],\n",
              " [10, 6, 0.8518518518518519, 0.9328537170263789],\n",
              " [11, 6, 0.8518518518518519, 0.9328537170263789],\n",
              " [4, 7, 0.8765432098765432, 0.894484412470024],\n",
              " [5, 7, 0.8765432098765432, 0.894484412470024],\n",
              " [7, 7, 0.8754208754208754, 0.894484412470024],\n",
              " [9, 7, 0.8742985409652076, 0.894484412470024],\n",
              " [3, 7, 0.877665544332211, 0.8896882494004796],\n",
              " [2, 7, 0.877665544332211, 0.8872901678657075],\n",
              " [14, 8, 0.8720538720538721, 0.8800959232613909],\n",
              " [11, 10, 0.8900112233445566, 0.8776978417266187],\n",
              " [6, 4, 0.835016835016835, 0.8752997601918465],\n",
              " [8, 4, 0.835016835016835, 0.8752997601918465],\n",
              " [9, 4, 0.835016835016835, 0.8752997601918465],\n",
              " [10, 4, 0.835016835016835, 0.8752997601918465],\n",
              " [11, 4, 0.835016835016835, 0.8752997601918465],\n",
              " [11, 8, 0.8742985409652076, 0.8752997601918465],\n",
              " [12, 4, 0.835016835016835, 0.8752997601918465],\n",
              " [12, 10, 0.8877665544332211, 0.8752997601918465],\n",
              " [13, 4, 0.835016835016835, 0.8752997601918465],\n",
              " [14, 4, 0.835016835016835, 0.8752997601918465],\n",
              " [2, 5, 0.8462401795735129, 0.8729016786570744],\n",
              " [5, 5, 0.8462401795735129, 0.8729016786570744],\n",
              " [6, 10, 0.9046015712682379, 0.8729016786570744],\n",
              " [7, 5, 0.8451178451178452, 0.8729016786570744],\n",
              " [8, 5, 0.8451178451178452, 0.8729016786570744],\n",
              " [10, 5, 0.8451178451178452, 0.8729016786570744],\n",
              " [13, 5, 0.8451178451178452, 0.8729016786570744],\n",
              " [13, 8, 0.8765432098765432, 0.8729016786570744],\n",
              " [6, 8, 0.8843995510662177, 0.8705035971223022],\n",
              " [10, 10, 0.8956228956228957, 0.8705035971223022],\n",
              " [11, 9, 0.8877665544332211, 0.8705035971223022],\n",
              " [12, 8, 0.8765432098765432, 0.8705035971223022],\n",
              " [12, 9, 0.8855218855218855, 0.8705035971223022],\n",
              " [3, 8, 0.8900112233445566, 0.86810551558753],\n",
              " [5, 9, 0.8967452300785634, 0.86810551558753],\n",
              " [7, 8, 0.8821548821548821, 0.86810551558753],\n",
              " [8, 8, 0.8821548821548821, 0.86810551558753],\n",
              " [10, 8, 0.877665544332211, 0.86810551558753],\n",
              " [14, 9, 0.8821548821548821, 0.86810551558753],\n",
              " [14, 10, 0.8855218855218855, 0.86810551558753],\n",
              " [2, 6, 0.856341189674523, 0.8657074340527577],\n",
              " [4, 8, 0.8888888888888888, 0.8657074340527577],\n",
              " [5, 6, 0.856341189674523, 0.8657074340527577],\n",
              " [7, 6, 0.8552188552188552, 0.8657074340527577],\n",
              " [9, 6, 0.8540965207631874, 0.8657074340527577],\n",
              " [12, 6, 0.8518518518518519, 0.8657074340527577],\n",
              " [13, 6, 0.8518518518518519, 0.8657074340527577],\n",
              " [13, 9, 0.8832772166105499, 0.8657074340527577],\n",
              " [2, 9, 0.9012345679012346, 0.8633093525179856],\n",
              " [5, 8, 0.8855218855218855, 0.8633093525179856],\n",
              " [9, 8, 0.8832772166105499, 0.8633093525179856],\n",
              " [2, 8, 0.8900112233445566, 0.8609112709832134],\n",
              " [4, 10, 0.9113355780022446, 0.8609112709832134],\n",
              " [10, 11, 0.9068462401795735, 0.8609112709832134],\n",
              " [12, 11, 0.8978675645342312, 0.8609112709832134],\n",
              " [13, 10, 0.8877665544332211, 0.8609112709832134],\n",
              " [13, 12, 0.9012345679012346, 0.8609112709832134],\n",
              " [14, 11, 0.8911335578002245, 0.8609112709832134],\n",
              " [14, 12, 0.8945005611672279, 0.8609112709832134],\n",
              " [14, 13, 0.8945005611672279, 0.8609112709832134],\n",
              " [14, 14, 0.9023569023569024, 0.8609112709832134],\n",
              " [2, 10, 0.9147025813692481, 0.8585131894484412],\n",
              " [6, 9, 0.8956228956228957, 0.8585131894484412],\n",
              " [7, 9, 0.8956228956228957, 0.8585131894484412],\n",
              " [9, 9, 0.8922558922558923, 0.8585131894484412],\n",
              " [11, 11, 0.9023569023569024, 0.8585131894484412],\n",
              " [4, 9, 0.8978675645342312, 0.8561151079136691],\n",
              " [13, 13, 0.8967452300785634, 0.8561151079136691],\n",
              " [13, 14, 0.9046015712682379, 0.8561151079136691],\n",
              " [14, 7, 0.8641975308641975, 0.8561151079136691],\n",
              " [5, 10, 0.9068462401795735, 0.8537170263788969],\n",
              " [6, 7, 0.8720538720538721, 0.8537170263788969],\n",
              " [9, 10, 0.8967452300785634, 0.8537170263788969],\n",
              " [12, 13, 0.9012345679012346, 0.8537170263788969],\n",
              " [13, 7, 0.8653198653198653, 0.8537170263788969],\n",
              " [13, 11, 0.8933782267115601, 0.8537170263788969],\n",
              " [3, 9, 0.9001122334455668, 0.8513189448441247],\n",
              " [8, 7, 0.8698092031425365, 0.8513189448441247],\n",
              " [8, 9, 0.8911335578002245, 0.8513189448441247],\n",
              " [8, 10, 0.8978675645342312, 0.8513189448441247],\n",
              " [10, 7, 0.8664421997755332, 0.8513189448441247],\n",
              " [10, 9, 0.8866442199775533, 0.8513189448441247],\n",
              " [11, 7, 0.8664421997755332, 0.8513189448441247],\n",
              " [11, 13, 0.9046015712682379, 0.8513189448441247],\n",
              " [12, 7, 0.8653198653198653, 0.8513189448441247],\n",
              " [12, 12, 0.9012345679012346, 0.8513189448441247],\n",
              " [12, 14, 0.9046015712682379, 0.8513189448441247],\n",
              " [3, 10, 0.9124579124579124, 0.8489208633093526],\n",
              " [6, 11, 0.9191919191919192, 0.8489208633093526],\n",
              " [7, 10, 0.9012345679012346, 0.8489208633093526],\n",
              " [7, 11, 0.9147025813692481, 0.8489208633093526],\n",
              " [9, 11, 0.9079685746352413, 0.8465227817745803],\n",
              " [11, 12, 0.9068462401795735, 0.8465227817745803],\n",
              " [8, 11, 0.9147025813692481, 0.8441247002398081],\n",
              " [11, 14, 0.9079685746352413, 0.8441247002398081],\n",
              " [2, 11, 0.9349046015712682, 0.841726618705036],\n",
              " [4, 11, 0.9304152637485971, 0.8393285371702638],\n",
              " [3, 11, 0.9326599326599326, 0.8369304556354916],\n",
              " [5, 11, 0.9248035914702581, 0.8369304556354916],\n",
              " [10, 12, 0.9124579124579124, 0.8369304556354916],\n",
              " [9, 12, 0.9135802469135802, 0.8345323741007195],\n",
              " [10, 13, 0.9135802469135802, 0.8345323741007195],\n",
              " [10, 14, 0.9158249158249159, 0.8345323741007195],\n",
              " [6, 12, 0.9292929292929293, 0.829736211031175],\n",
              " [8, 12, 0.9214365881032548, 0.829736211031175],\n",
              " [2, 2, 0.7867564534231201, 0.8273381294964028],\n",
              " [2, 13, 0.957351290684624, 0.8273381294964028],\n",
              " [3, 2, 0.7867564534231201, 0.8273381294964028],\n",
              " [4, 2, 0.7867564534231201, 0.8273381294964028],\n",
              " [5, 2, 0.7867564534231201, 0.8273381294964028],\n",
              " [6, 2, 0.7867564534231201, 0.8273381294964028],\n",
              " [7, 2, 0.7867564534231201, 0.8273381294964028],\n",
              " [7, 12, 0.9225589225589226, 0.8273381294964028],\n",
              " [8, 2, 0.7867564534231201, 0.8273381294964028],\n",
              " [9, 2, 0.7867564534231201, 0.8273381294964028],\n",
              " [10, 2, 0.7867564534231201, 0.8273381294964028],\n",
              " [11, 2, 0.7867564534231201, 0.8273381294964028],\n",
              " [12, 2, 0.7867564534231201, 0.8273381294964028],\n",
              " [13, 2, 0.7867564534231201, 0.8273381294964028],\n",
              " [14, 2, 0.7867564534231201, 0.8273381294964028],\n",
              " [3, 13, 0.9494949494949495, 0.8249400479616307],\n",
              " [6, 13, 0.9326599326599326, 0.8249400479616307],\n",
              " [8, 13, 0.9236812570145904, 0.8249400479616307],\n",
              " [2, 12, 0.9517396184062851, 0.8225419664268585],\n",
              " [5, 12, 0.9315375982042648, 0.8225419664268585],\n",
              " [7, 13, 0.9236812570145904, 0.8225419664268585],\n",
              " [9, 13, 0.9147025813692481, 0.8201438848920863],\n",
              " [9, 14, 0.9169472502805837, 0.8201438848920863],\n",
              " [3, 12, 0.9438832772166106, 0.8177458033573142],\n",
              " [5, 13, 0.936026936026936, 0.8177458033573142],\n",
              " [7, 14, 0.9270482603815937, 0.8177458033573142],\n",
              " [4, 13, 0.9438832772166106, 0.8105515587529976],\n",
              " [4, 12, 0.9427609427609428, 0.8081534772182254],\n",
              " [8, 14, 0.9225589225589226, 0.8081534772182254],\n",
              " [5, 14, 0.9427609427609428, 0.8057553956834532],\n",
              " [6, 14, 0.936026936026936, 0.8033573141486811],\n",
              " [3, 14, 0.9607182940516273, 0.7985611510791367],\n",
              " [4, 14, 0.9528619528619529, 0.7961630695443646],\n",
              " [2, 14, 0.9629629629629629, 0.7841726618705036]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sp-shfD5ucd"
      },
      "source": [
        "Получился очень интересный результат: моя модель и модель из sklearn при глубине дерева, равной единице, верно классифицирует все тестовые наблюдения."
      ]
    }
  ]
}